{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter data to only include the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load testing ids\n",
    "with open('./data/fisher.txt', 'r') as file:\n",
    "    fids = file.read().split('\\n')\n",
    "    fids = [x for x in fids if x]\n",
    "\n",
    "# load the json file with the processed data\n",
    "with open('./data/processed_data.json',\n",
    "            'r') as file:\n",
    "        res = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the utterances that are in the testing set\n",
    "res2 = {'utterances': [x for x in res['utterances'] if x['utterance_id'] in fids]}\n",
    "\n",
    "with open('./data/processed_data_test.json', 'w') as file:\n",
    "    json.dump(res2, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to split the data into prompts and completions. We will use the `train_data_prep.py` script to do this. The script will take the input data and output prompts and completions in the format required by the model. The script will also add the speaker information to the prompts and completions from hyp_spk and hyp_spk_oracle fields in the input data.\n",
    "\n",
    "```shell\n",
    "python3 train_data_prep.py \\\n",
    "--input=\"./data/processed_data_test.json\" \\\n",
    "--output=\"./data/prompts_test.jsonl\" \\\n",
    "--output_type=jsonl \\\n",
    "--emit_input_length=2500 \\\n",
    "--emit_target_length=2500 \\\n",
    "--prompt_suffix=\"\" \\\n",
    "--completion_suffix=\"\" \\\n",
    "--input_feature_key=\"prompt\" \\\n",
    "--output_feature_key=\"completion\" \\\n",
    "--text_field=\"hyp_text\" \\\n",
    "--input_speaker_field=\"hyp_spk\" \\\n",
    "--target_speaker_field=\"hyp_spk_oracle\" \\\n",
    "--speaker_prefix=\"<spk:\"\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to re-insert the prompts and completions into the input data to be able to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/prompts_test.jsonl', 'r') as file:\n",
    "    data = [json.loads(x) for x in file]\n",
    "\n",
    "with open('./data/processed_data_test.json', 'r') as file:\n",
    "    res = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "for i in tqdm(range(len(res['utterances']))):\n",
    "    res['utterances'][i]['completions_ref'] = []\n",
    "    res['utterances'][i]['completions_llm'] = []\n",
    "    res['utterances'][i]['prompts'] = []\n",
    "\n",
    "    while True:\n",
    "        # access data at index j\n",
    "        utt_id = data[j]['utterance_id'].split('_seg')[0]\n",
    "        if utt_id != res['utterances'][i]['utterance_id']:\n",
    "            break\n",
    "\n",
    "        # append the data to the lists\n",
    "        res['utterances'][i]['completions_ref'].append(data[j]['completion'])\n",
    "        res['utterances'][i]['prompts'].append(data[j]['prompt'])\n",
    "\n",
    "        j += 1\n",
    "        if j == len(data):\n",
    "           break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the processed json\n",
    "with open('./data/full_test.json', 'w') as file:\n",
    "    json.dump(res, file)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
