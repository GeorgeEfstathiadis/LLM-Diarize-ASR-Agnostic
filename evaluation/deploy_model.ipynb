{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f07528e2-82cd-4ef3-a5b5-81f6ea71682a",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e82a1a-c639-46e7-a5fe-1eaa63235c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import concurrent\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57774e9-38cc-401e-9c5e-341294867643",
   "metadata": {},
   "source": [
    "# Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a1333f-23c9-401e-99c4-5430b2fa0809",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"model_id\"\n",
    "\n",
    "# sagemaker config\n",
    "instance_type = \"ml.g5.12xlarge\"\n",
    "number_of_gpu = 4\n",
    "health_check_timeout = 300\n",
    "\n",
    "config = {\n",
    "  'HF_MODEL_ID': \"/opt/ml/model\", # path to where sagemaker stores the model\n",
    "  'SM_NUM_GPUS': json.dumps(number_of_gpu), # Number of GPU used per replica\n",
    "  'MAX_INPUT_LENGTH': json.dumps(2048), # Max length of input text\n",
    "  'MAX_TOTAL_TOKENS': json.dumps(4096) # Max length of the generation (including input text)\n",
    "}\n",
    "\n",
    "# create HuggingFaceModel with the image uri\n",
    "llm_model = HuggingFaceModel(\n",
    "    role=role,\n",
    "    model_data={'S3DataSource':{'S3Uri': f's3://{sagemaker_session_bucket}/{model_id}/output/model/','S3DataType': 'S3Prefix','CompressionType': 'None'}},\n",
    "    image_uri=get_huggingface_llm_image_uri(\"huggingface\",version=\"1.4.2\"),\n",
    "    env=config\n",
    ")\n",
    "\n",
    "# Deploy model to an endpoint\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy\n",
    "llm = llm_model.deploy(\n",
    "  initial_instance_count=1,\n",
    "  instance_type=instance_type,\n",
    "  container_startup_health_check_timeout=health_check_timeout, # 10 minutes to be able to load the model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e290bd3-9580-4669-ae95-dbfc6f120807",
   "metadata": {},
   "source": [
    "# Prompts - Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af91af7b-6172-4e44-84a6-7a46c528bacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/prompts_test.jsonl', 'r') as file:\n",
    "    data = [json.loads(x) for x in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3ac1ad-91b6-4f91-a7b8-dfdaf38c9d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "format = \"\"\"### Instruction\n",
    "In the speaker diarization transcript below, some words are potentially misplaced. Please correct those words and move them to the right speaker. Directly show the corrected transcript without explaining what changes were made or why you made those changes.:\n",
    "\n",
    "{{ user_msg_1 }}\n",
    "\n",
    "### Answer\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "test_inputs = []\n",
    "\n",
    "for _, test_entry in enumerate(data):\n",
    "    id = test_entry['utterance_id']\n",
    "    prompt = test_entry['prompt']\n",
    "    payload = {\"id\": id,\"inputs\": format.replace(\"{{ user_msg_1 }}\", prompt), \"parameters\": {\"max_new_tokens\":2048, \"top_p\":0.5, \"temperature\":0.2, \"stop\":[\"</s>\", \"###\"]}}\n",
    "    test_inputs.append(payload)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0dbcbb",
   "metadata": {},
   "source": [
    "# Prompts - Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b55b01-665d-453e-96be-c6f4abef5c43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "workers = 5\n",
    "print(f\"workers used for load test: {workers}\")\n",
    "responses = {}\n",
    "max_retries = 3  # Maximum number of retries for each request\n",
    "\n",
    "def submit_task(executor, index, payload):\n",
    "    future = executor.submit(llm.predict, payload)\n",
    "    future_to_index[future] = (index, payload, 0)  # Adding retry count 0 initially\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=workers) as executor:\n",
    "    future_to_index = {}\n",
    "    pbar = tqdm(total=len(test_inputs))  # Initialize the progress bar\n",
    "\n",
    "    for i in range(len(test_inputs)):\n",
    "        payload = {\n",
    "            \"inputs\": test_inputs[i]['inputs'],\n",
    "            \"parameters\": test_inputs[i]['parameters']\n",
    "        }\n",
    "        submit_task(executor, test_inputs[i][\"id\"], payload)\n",
    "\n",
    "    while future_to_index:\n",
    "        for future in concurrent.futures.as_completed(future_to_index):\n",
    "            index, payload, retries = future_to_index.pop(future)\n",
    "            try:\n",
    "                result = future.result()  # This gets the result from the future\n",
    "                responses[index] = result[0][\"generated_text\"]\n",
    "                pbar.update(1)  # Update the progress bar when a result is successfully added\n",
    "\n",
    "            except Exception as exc:\n",
    "                print(f'Task {index} generated an exception: {exc}')\n",
    "                if retries < max_retries:\n",
    "                    print(f\"Retrying task {index}, attempt {retries + 1}\")\n",
    "                    submit_task(executor, index, payload)  # Retry the task\n",
    "                else:\n",
    "                    print(f\"Task {index} failed after {retries} retries\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e9e3f-2e01-4224-8c88-2b87d6dfd566",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./results/model_predictions.json', 'w') as file:\n",
    "    json.dump(responses, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0985618",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee66e302-5cb5-4920-aedf-15b4ed9dd35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.delete_model()\n",
    "llm.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
